{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2 Engineering Design.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prahlad108/ME592-HW-Projects/blob/main/HW2_Engineering_Design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Homework 2 - Engineering Design Team**"
      ],
      "metadata": {
        "id": "YQzia7KRGa54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the code is not finished as we were having major issues, we will hopefully have an improved version for 3/10/2022 as per the teacher mentioning that it could be handed in then if we needed more time, however we will sumbit what we have to canvas first just incase"
      ],
      "metadata": {
        "id": "_SW8SAD3fK9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Moved from the above drive importing code that so that it could be run without interference\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n"
      ],
      "metadata": {
        "id": "psNz0ytqFyrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alex K\n",
        "#@DATE: 3/6/2022\n",
        "#@PURPOSE: This installs geomdl, the code that is commented out was supposed to import NURBS but I think it is not needed\n",
        "!pip3 install geomdl\n",
        "  # Importing NURBS module\n",
        "#from geomdl.core import NURBS\n",
        "  # Importing visualization module\n",
        "#from geomdl.visualization import VisMPL as vis"
      ],
      "metadata": {
        "id": "kYPU9eCIGAXu",
        "outputId": "6d2b5183-ece5-4a14-fdfe-2b545511299c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geomdl in /usr/local/lib/python3.7/dist-packages (5.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm not sure why but the above drive mounting had issues for me, what I did below worked for me, this part isn't terribly important as long as we can all get it working to run\n",
        "-Dan"
      ],
      "metadata": {
        "id": "MNdIY2ro9J1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dan\n",
        "#@DATE: 3/8/2022\n",
        "#@PURPOSE: This block will mount your google colab drive. Successful execution\n",
        "#         of the remainder of this code depends on a file structure of...\n",
        "#         /MyDrive/Colab Notebooks/ME 592/HW2/HW2.ipynb\n",
        "#         /MyDrive/Colab Notebooks/ME 592/HW2/data/[input_geometry/output_geometry]\n",
        "\n",
        "\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "# This mouunts your google drive to the current runtime\n",
        "drive.mount('/content/mnt', force_remount=True)\n",
        "# We define a notebook path\n",
        "nb_path = '/content/notebooks'\n",
        "# We create a symbolic link from our drive's default \"Colab Notebooks\" folder to nb_path\n",
        "os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "# Insert nb path\n",
        "sys.path.insert(0, nb_path)"
      ],
      "metadata": {
        "id": "_u0592zM8oMg",
        "outputId": "c23ab6e5-5fb8-425d-adf9-722a847cef8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mnt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below I just set up relative paths to where all of our data is stored. I made the assumption that we could all copy-paste the entire \"data\" folder into the same directory level as our HW2. I copied the folder structure Brian was using above and simply added it into my google drive since the relative paths will associate to our own google drive, not Brian's who own's the colab session. -Dan"
      ],
      "metadata": {
        "id": "C7ipVS899Xcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dan\n",
        "#@DATE: 3/8/2022\n",
        "#@PURPOSE: Establish filepaths for digging into directories after symbolic link\n",
        "\n",
        "# Filepath to the data folder\n",
        "dataFolder = nb_path + '/ME 592/HW2/data'\n",
        "#dataFolder = os.path.join(nb_path,'/ME 592/HW2/data')\n",
        "# Filepath to the input data folder\n",
        "inputFolder = dataFolder + '/input_geometry'\n",
        "#inputFolder = os.path.join(dataFolder, 'input_geometry')\n",
        "# Filepath to the output data folder\n",
        "outputFolder = dataFolder + '/final_geometry'\n",
        "#outputFolder = os.path.join(dataFolder,'final_geometry')"
      ],
      "metadata": {
        "id": "h9g3cFi98tOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "znNUnP97j31V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the meat of part 1 of the homework. I stored everything into one large data list of tuples. The tuples are formatted the same way that he recommended in the HW assignment. (input,output) where input is (mesh,time,temp,pres) and output is (mesh)\n",
        "each of the meshes are currently 3x12x17 (reversed from what he stated). We can mirrior this back to 17x12x3 pretty easily though\n",
        "\n",
        "Notes: I made an assumption that the output is to be read as the first 17 data lines are elements A[0-16][0][0], then the following 17 data lines would be A[17-31][1][0]... and so on until you loop around to the the next input mesh. \n",
        "\n",
        "If anyone has addt'l information on the anticipation of how to read this, I can help adjust, but I couldn't find anything that specified how to read it and made an assumption to get us started."
      ],
      "metadata": {
        "id": "jbkRXUvJ94yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@AUTHOR: Dan\n",
        "#@DATE: 3/8/2022\n",
        "#@PURPOSE: \n",
        "import natsort\n",
        "\n",
        "# Compile a list of the run directories in the input geometry folder\n",
        "runDirList = [dir for dir in os.listdir(inputFolder)]\n",
        "\n",
        "# Sorting the rundir list\n",
        "runDirList = natsort.natsorted(runDirList)\n",
        "\n",
        "# Compile a list of the final geometry data files\n",
        "outputList = [os.path.join(outputFolder,f) for f in os.listdir(outputFolder) if os.path.isfile(os.path.join(outputFolder,f))]\n",
        "\n",
        "# List of Pressures [mmHg]\n",
        "#pressList = ['76mmHg','80mmHg','84mmHg']\n",
        "pressList = ['p1','p2','p3']\n",
        "# List of Temperatures [Kelvin]\n",
        "#tempList = ['300K','350K','400K','450K','500K']\n",
        "tempList = ['t1','t2','t3','t4','t5']\n",
        "# List of Times [sec]\n",
        "timeList = ['80','140']\n",
        "# Initializing 3-D Data Array structure\n",
        "dataArray = [[[[ [] for _ in range(len(runDirList))] for _ in range(len(tempList))] \\\n",
        "              for _ in range(len(pressList))] for _ in range(len(timeList))]\n",
        "\n",
        "dataArrayParams = [[[[ [] for _ in range(len(runDirList))] for _ in range(len(tempList))] \\\n",
        "              for _ in range(len(pressList))] for _ in range(len(timeList))]\n",
        "\n",
        "# Data Array Structure Key \n",
        "dataArrayKey = [[[[ [time,press,temp,run] for run in runDirList] for temp in tempList] for press in pressList] for time in timeList]\n",
        "\n",
        "# OBE dataList\n",
        "dataList = []\n",
        "\n",
        "# loop through each run directory\n",
        "for runDir in runDirList:\n",
        "  \n",
        "  # Run Index from input file naming convention\n",
        "  runIdx = runDir[3:]\n",
        "  # Creating OS file path of the run directory\n",
        "  runDirPath = os.path.join(inputFolder, runDir)\n",
        "\n",
        "  # Checking for each file in the run directory\n",
        "  inputFileList = [os.path.join(runDirPath,f) for f in os.listdir(runDirPath) if os.path.isfile(os.path.join(runDirPath,f))]\n",
        "\n",
        "  # Initializing input geometry 17x12x3 array\n",
        "  inputGeometry = [[[ [] for _ in range(3)] for _ in range(12)] for _ in range (17)]\n",
        "  \n",
        "  # Input Mesh Index Counters\n",
        "  i = 0 \n",
        "  j = 0 \n",
        "  k = 0\n",
        "\n",
        "  for input in inputFileList:\n",
        "    \n",
        "    with open(input) as file:\n",
        "      lines = [line.rstrip('\\n') for line in file]\n",
        "\n",
        "    for l in range(len(lines)):\n",
        "\n",
        "      if l > 4 and l != len(lines)-1:\n",
        "        \n",
        "        k = (l-5) % 17\n",
        "\n",
        "        if k == 0 and l > 5:\n",
        "          j = j + 1\n",
        "\n",
        "        line = lines[l].split()[:-1]\n",
        "\n",
        "        line = [float(n) for n in line]\n",
        "\n",
        "        inputGeometry[k][j][i] = line\n",
        "\n",
        "    i = i + 1\n",
        "    j = 0\n",
        "    k = 0\n",
        "\n",
        "  for time in timeList:\n",
        "    for press in pressList:\n",
        "      for temp in tempList:\n",
        "        # Mapping the input to output geometry files\n",
        "        outputFiles = [f for f in outputList if f.split('_')[-1] == str(runIdx) \\\n",
        "                       and f.split('_')[-2] == press \\\n",
        "                       and f.split('_')[-3] == temp \\\n",
        "                       and f.split('_')[-4] == time]\n",
        "\n",
        "        outputGeometry = [[[ [] for _ in range(3)] for _ in range(12)] for _ in range (17)]\n",
        "\n",
        "        # Output Mesh Index Counters\n",
        "        i = 0 \n",
        "        j = 0 \n",
        "        k = 0\n",
        "\n",
        "        if len(outputFiles) != 1:\n",
        "          #print('Output Mapping contains multiple solutions')\n",
        "          #print('missing data [run#, time, press, temp]:',runIdx,time,press,temp)\n",
        "          outputGeometry = [[[ [-9999] for _ in range(3)] for _ in range(12)] for _ in range (17)]\n",
        "\n",
        "        else:\n",
        "          with open(outputFiles[0]) as file:\n",
        "            lines = [line.rstrip('\\n') for line in file]\n",
        "          \n",
        "          for l in range(len(lines)):\n",
        "            \n",
        "            # Skipping the first line of meta data\n",
        "            if l == 0:\n",
        "              continue\n",
        "            \n",
        "            line = lines[l].split()\n",
        "\n",
        "            k = (l-1) % 17\n",
        "\n",
        "            if k == 0 and l > 5:\n",
        "              j = j + 1\n",
        "\n",
        "            if (l-1)%(12*17) == 0 and l > 2:\n",
        "              i = i + 1\n",
        "              j = 0\n",
        "              k = 0\n",
        "\n",
        "            line = [float(n) for n in line]\n",
        "\n",
        "            outputGeometry[k][j][i] = line\n",
        "\n",
        "          # Format data as a tuple of input and outputs and lists\n",
        "          input = [inputGeometry, temp, press]\n",
        "          output = [outputGeometry]\n",
        "          dataElement = (input,output)\n",
        "        \n",
        "        # Data array without additional Tuple Parameters\n",
        "        dataArrayParams[timeList.index(time)][pressList.index(press)][tempList.index(temp)][runDirList.index(runDir)] = dataElement\n",
        "        \n",
        "        input = [inputGeometry]\n",
        "        dataElement = (input,output)\n",
        "        # Data array with pressure, temperature in input tuple parameters\n",
        "        dataArray[timeList.index(time)][pressList.index(press)][tempList.index(temp)][runDirList.index(runDir)] = dataElement\n",
        "        "
      ],
      "metadata": {
        "id": "Ki-KnAj889zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example structure of compiled 3-D data array of (input,output) tuple run-keys\n",
        "import os\n",
        "# List of Pressures [mmHg]\n",
        "#pressList = ['76mmHg','80mmHg','84mmHg']\n",
        "pressList = ['p1','p2','p3']\n",
        "\n",
        "# List of Temperatures [Kelvin]\n",
        "#tempList = ['300K','350K','400K','450K','500K']\n",
        "tempList = ['t1','t2','t3','t4','t5']\n",
        "\n",
        "# List of Times [sec]\n",
        "timeList = ['80','140']\n",
        "\n",
        "import natsort\n",
        "runDirList = [dir for dir in os.listdir(inputFolder)]\n",
        "runDirList = natsort.natsorted(runDirList)\n",
        "\n",
        "dataArrayKey = [[[[ [time,press,temp,run] for run in runDirList] for _ in tempList] for _ in pressList] for _ in timeList]\n",
        "\n",
        "dataArrayExample = [[[[ [] for _ in range(len(runDirList))] for _ in range(len(tempList))] \\\n",
        "              for _ in range(len(pressList))] for _ in range(len(timeList))]\n",
        "\n",
        "# Example of keying into the data array:\n",
        "# Time 80, Temperature 1, Pressure 2 runs\n",
        "# dataArrayExample[timeList.index('80')][pressList.index('p1')][tempList.index('t1')][:]\n",
        "\n",
        "'''\n",
        "To parse through the files I kept the list correlated to the run output file \n",
        "naming format, see above for what each 'p1', or 't1' if desired we can also \n",
        "easily do a replace across the data structure to what those \"truely\" mean \n",
        "\n",
        "Last we can do list comprehension on this such as... below to get all times for \n",
        "p1, t1, and run1\n",
        "\n",
        "NOTE: the rundir list are named as folder structures are, e.g. \"run1\"... \"run64\"\n",
        "'''\n",
        "\n",
        "# dataArrayExample[:][pressList.index('p1')][tempList.index('t1')][runDirList.index('run1')]\n",
        "\n",
        "'''\n",
        "A given element in the 4-D array is a Tuple of (input,output)\n",
        "\n",
        "To key into the tuple we then need to key even deeper into the tuple\n",
        "\n",
        "I'm going to explain this relative to the tuple pulled out of the array, but\n",
        "this can easily be done by thinking of our 4-D array as actually a 4-D array of\n",
        "2-D arrays of 3-D arrays.\n",
        "\n",
        "remember here: the input = [ [17x12x3], [1,], [1,] ]\n",
        "          and the output = [ [17x12x3] ]\n",
        "          identical to how HW2 part 1 is showing if that explanation helps more\n",
        "'''\n",
        "\n",
        "# Pulling an (input,output) tuple out of our 4-D run-matrix\n",
        "myTuple = dataArray[0][0][0][0]\n",
        "\n",
        "# Looking at the input portion of the tuple\n",
        "myTupleInput = myTuple[0]\n",
        "\n",
        "# Looking at the input press, temp of the tuple\n",
        "myTupleInputGeometry = myTuple[0][1]\n",
        "myTupleInputGeometry = myTuple[0][2]\n",
        "\n",
        "# Looking at the input geometry of the tuple\n",
        "myTupleInputGeometry = myTuple[0][0]\n",
        "\n",
        "# Looking at the output geometry of the tuple\n",
        "myTupleOutputGeometry = myTuple[1][0]\n"
      ],
      "metadata": {
        "id": "IwzX-EkooyQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "48d7e531-7341-4ada-c100-63ff912b5081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-30c85ede9c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Looking at the input press, temp of the tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mmyTupleInputGeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mmyTupleInputGeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we are trying to take the data Dan created and perform the PCA whitening on it for problem 2."
      ],
      "metadata": {
        "id": "pxaOcjR0p-ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Alex K and Prahlad P\n",
        "#@DATE: 3/9/2022\n",
        "#@PURPOSE: Attempting to solve problem 2\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "#Used to adjust n_components parameter for pca whitening (it also adjust some array sizes as needed for this as well)\n",
        "#Causes pca whitening to put out a 17xn data set\n",
        "n = 2\n",
        "\n",
        "#Create empty 8D array where we have the 17xn data at the end which will contain the PCA whitened data for xyz and specific smesh files\n",
        "#The number for the sixth component of dataArrayWhitened corresponds to the number used for n_components, will be called PCA whitened data 2 in structure\n",
        "#dataArrayWhitened Structure [time, pressure, temperature, run, PCA whitened data 1, PCA whitened data 2,xyz channels, which smesh file]\n",
        "dataArrayWhitened = np.zeros([2,3,5,64,17,n,3,3])\n",
        "\n",
        "#Data array values size is 2x3x5x64\n",
        "a = 0 \n",
        "b = 0\n",
        "c = 0\n",
        "d = 0\n",
        "for a in range(2):\n",
        "  for b in range(3):\n",
        "    for c in range(5):\n",
        "      for d in range(64):\n",
        "###############################################################################\n",
        "        #Create array from list of size 17x12x3x3 for doing transform on\n",
        "        #arr structure = [image data 1, image data 2, xyz channels, smesh file]\n",
        "        arr = np.array(dataArray[a][b][c][d][0][0])\n",
        "\n",
        "        #Create array pcaOut used for storing pca results which get inerted into the output dataArrayWhitened 8D array with the PCA whitened Data\n",
        "        #Note that the second number of pcaOut corresponds to the number set for n_components\n",
        "        pcaOut = np.zeros([17,n,3,3])\n",
        "        \n",
        "        #Loops through the three smesh files\n",
        "        i = 0\n",
        "        for i in range(3):\n",
        "          #Does the PCA transform on the x, y, and z planes of a given smesh file i\n",
        "          pca = PCA(n_components=n,svd_solver='auto', whiten=True)\n",
        "          pcaOut[:,:,0,i] = pca.fit_transform(arr[:,:,0,i])\n",
        "          pcaOut[:,:,1,i] = pca.fit_transform(arr[:,:,1,i])\n",
        "          pcaOut[:,:,2,i] = pca.fit_transform(arr[:,:,2,i])\n",
        "          i = i + 1\n",
        "        dataArrayWhitened[a][b][c][d] = pcaOut\n",
        "###############################################################################\n",
        "        d = d + 1\n",
        "      d = 0\n",
        "      c = c + 1\n",
        "    c = 0\n",
        "    b = b + 1\n",
        "  b = 0\n",
        "  a=a+1\n",
        "\n",
        "print(dataArrayWhitened.shape)"
      ],
      "metadata": {
        "id": "sGOHPfOK4FXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c9a79e-d1d9-4252-bc1e-5a981dd32d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 5, 64, 17, 2, 3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Alex K and Prahlad P\n",
        "#@DATE: 3/9/2022\n",
        "#@PURPOSE: Attempting to solve/work on Problem 3\n",
        "!pip install -q keras \n",
        "\n",
        "from google.colab import drive\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.datasets import load_digits\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "outputPath = '/content/drive/MyDrive/ME592/HW2/data/final_geometry'\n",
        "#!ls '/content/drive/MyDrive/ME592/HW2/data/final_geometry'\n",
        "\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "palette = sns.color_palette('bright', 10)\n",
        "\n",
        "X,y = load_digits(return_X_y=True)\n",
        "MACHINE_EPSILON = np.finfo(np.double).eps\n",
        "n_components = 2\n",
        "perplexity = 30\n",
        "\n",
        "def fit(X):\n",
        "  n_samples = X.shape[0]\n",
        "  dist = pairwise_distances(X, metric='euclidean', squared=True) #euclidian distance\n",
        "  P = joint_probabilities(distances=dist, desired_perplexity=perplexity, verbose=False) #joint probabilities from distances p_i,j\n",
        "  X_embedded = 1e-4*(np.random.mtrand.rand.randn(n_samples, n_components).astype(np.float32))\n",
        "  dof = n_components-1\n",
        "  return _tsne(P, dof, n_samples, X_embedded=X_embedded)\n",
        "\n",
        "def _tsne(P, dof, n_samples, X_embedded):\n",
        "  params = X_embedded.ravel()\n",
        "  obj_func =_kl_divergence\n",
        "  params = _gradient_descent(obj_func, params, [P, dof, n_samples, n_components])\n",
        "  return X_embedded\n",
        "\n",
        "g = np.random.rand(17,12)\n",
        "np.ravel(g)\n",
        "\n",
        "def _kl_divergence(params, P, dof, n_samples, n_components):\n",
        "  X_embedded = params.reshape(n_samples, n_components)\n",
        "  d = pdist(X_embedded, 'sqeuclidean')\n",
        "  d /= dof\n",
        "  d += 1\n",
        "  d **= (d + 1.0)/-2.0\n",
        "  q = np.maximum(d/2.0*np.sum(d), MACHINE_EPSILON)\n",
        "  kl_divergence = 2.0 * np.dot(P, np.log(np.maximum(P, MACHINE_EPSILON) / q))\n",
        "\n",
        "  grad = np.ndarray((n_samples, n_components), dtype=params.dtype)\n",
        "  pqd = squareform((P-q)*d)\n",
        "  for i in range(n_samples):\n",
        "    grad[i] = np.dot(np.ravel(pqd[i], order='K'), X_embedded[i]-X_embedded)\n",
        "  grad = grad.ravel()\n",
        "  v = 2.0*(dof+1.0)/dof\n",
        "  grad *= v\n",
        "\n",
        "  return kl_divergence, grad\n",
        "\n",
        "def _gradient_descent(obj_func, h0, args, it=0, n_iter=1000, n_iter_check=1, n_iter_without_progress=300, momentum=0.75, learning_rate=200.0, min_gain=0.01, min_grad_norm=1e-7):\n",
        "    h = h0.copy().ravel()\n",
        "    update = np.zeros_like(h)\n",
        "    gains = np.ones_like(h)\n",
        "    err = np.finfo(np.float).max\n",
        "    best_err = np.finfo(np.float).max\n",
        "    best_iter = i = it\n",
        "\n",
        "    for i in range(it, n_iter):\n",
        "      err, grad=obj_func(h, *args)\n",
        "      grad_norm = linalg.norm(grad)\n",
        "\n",
        "      increase = update*grad<0.0\n",
        "      decrease = np.invert(increase)\n",
        "      gains[increase] += 0.2\n",
        "      gains[decrease] *= 0.8\n",
        "      np.clip(gains, min_gain, np.inf, out=gains)\n",
        "      grad *= gains\n",
        "      update = momentum*update - learning_rate*grad\n",
        "      h += update\n",
        "\n",
        "      print('[t-sne] Iteration %d: err=%0.7f', 'gradient norm=%0.7f' % (i+1, err, grad_norm))\n",
        "\n",
        "      if err < best_err:\n",
        "        best_err = err\n",
        "        best_iter = 1\n",
        "      elif i - best_iter > n_iter_without_progress:\n",
        "        break\n",
        "      if grad_norm <= min_grad_norm:\n",
        "        break\n",
        "      return h\n",
        "\n",
        "X_embedded = fit(X)\n",
        "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full', palette=palette)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pnpUovxKuxCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AX7QImQMgg7w"
      }
    }
  ]
}